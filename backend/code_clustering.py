import pandas as pd
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, silhouette_samples
import numpy as np

# Class for code clustering
class CodeClusterer:
    def __init__(self, num_clusters):
        self.num_clusters = num_clusters  # Store the number of clusters
        self.data = None  # Placeholder for the input data DataFrame
        self.model = KMeans(n_clusters=num_clusters, random_state=42)  # Initialize KMeans model with specified clusters
        self.elbow_scores = []  # Initialize an empty list to store elbow scores (inertia values)
        self.silhouette_avg = None  # Initialize placeholder for average silhouette score
        self.davies_bouldin = None  # Initialize placeholder for Davies-Bouldin score

    def load_data(self, dataframe):
        self.data = dataframe  # Assign the provided DataFrame to the class attribute

    def cluster_codes(self):
        # Check if data is loaded and not empty
        if self.data is None or self.data.empty:
            raise ValueError("DataFrame is empty or not loaded.")  # Raise an error if data is not loaded or is empty

        # Select features for clustering (only the similarity columns are used)
        features = self.data[['Text_Similarity_%', 'Structural_Similarity_%', 'Weighted_Similarity_%']]
        # Fit the KMeans model to the selected features
        self.model.fit(features)

        # Assign the cluster labels generated by KMeans to a new column 'Cluster' in the DataFrame
        self.data['Cluster'] = self.model.labels_

        # Calculate the average silhouette score for the clustering
        self.silhouette_avg = silhouette_score(features, self.model.labels_)

        # Calculate the Davies-Bouldin score for the clustering
        self.davies_bouldin = davies_bouldin_score(features, self.model.labels_)

        return features  # Return the DataFrame with the selected features

    def get_clustered_data(self):
        return self.data  # Return the DataFrame with clusters assigned

    def calculate_elbow(self, max_clusters=10):
        # Check if data is loaded and not empty
        if self.data is None or self.data.empty:
            raise ValueError("DataFrame is empty or not loaded.")  # Raise an error if data is not loaded or is empty

        # Select features for calculating elbow scores
        features = self.data[['Text_Similarity_%', 'Structural_Similarity_%', 'Weighted_Similarity_%']]

        # Iterate through a range of cluster numbers from 2 to max_clusters
        for i in range(2, max_clusters + 1):
            model = KMeans(n_clusters=i, random_state=42)  # Initialize KMeans with the current cluster count
            model.fit(features)  # Fit the model to the data
            self.elbow_scores.append(model.inertia_)  # Append the inertia (elbow score) to the list

    def get_silhouette_data(self, features):
        # Calculate silhouette values for each sample in the DataFrame
        return pd.DataFrame({
            'Cluster': self.data['Cluster'],  # Assign cluster labels
            'Silhouette Value': silhouette_samples(features, self.data['Cluster'])  # Calculate silhouette values
        })

# Function to find the elbow point in the elbow scores
def find_elbow_point(elbow_scores):
    # Return a default value if elbow scores are empty
    if not elbow_scores:
        return 2  # Return 2 as a default value if the list is empty

    # Calculate the change in inertia between consecutive cluster sizes
    changes = np.diff(elbow_scores)  # Compute the difference between successive inertia values

    # Identify the cluster size with the maximum change in inertia
    return np.argmin(changes) + 2  # Find the index with the maximum change, adjust by +2 to get the correct cluster number
